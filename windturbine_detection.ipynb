{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "1. Implement option for single prediction\n",
    "1. Write doc strings for every function\n",
    "1. Exception handling and check for invalid inputs.(most important! requirement of kernel_sizes and layer_activatons have to have the same amount of elements as the number of layers (num_cnn_layers)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score    \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindturbineDetector():\n",
    "    \n",
    "    def __init__(self, selection_windturbine_paths=[\"\"], selection_no_windturbine_paths=[\"\"], \n",
    "                 categories_windturbine_crops=[3], categories_no_windturbine_crops=[2], \n",
    "                 pixel=\"30p\", image_bands=[\"B02\", \"B03\", \"B04\", \"B08\"], rescale_factor=2**14, \n",
    "                 rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1,\n",
    "                 horizontal_flip=False, vertical_flip=False, fill_mode=\"constant\", cval=0.0,\n",
    "                 num_cnn_layers=2, filters=16, kernel_sizes=[5, 5], layer_activations=[\"relu\", \"relu\"],\n",
    "                 input_shape=[30, 30, 4], pool_size=2, strides=2, full_connection_units=128, \n",
    "                 full_connection_activation=\"relu\", output_units=1, output_activation=\"sigmoid\",\n",
    "                 optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"], epochs=10):\n",
    "        \n",
    "            \"\"\"\n",
    "            initialize all parameters for the data preparation\n",
    "            \n",
    "            Parameters for data import\n",
    "            ----------\n",
    "            categories_windturbine_crops: list, [1,2,3]\n",
    "                Set one or more categories of selection for windturbine selection. \n",
    "                Default is [3]\n",
    "            categories_no_windturbine_crops: list, [1,2]\n",
    "                Set one or more categories of selection for random crop selection. \n",
    "                Default is [2]\n",
    "            pixel: str, (\"10p\", \"20p\", \"30p\", \"40p\" or \"50p\")\n",
    "                Set one pixel value for the image.\n",
    "                Default is \"30p\"\n",
    "            selection_windturbines_path: pathlib.Path, pathlib.Path(\"\")\n",
    "                Set a list of paths to selection_windturbine folders in pathlib.Path format following the folder convention.\n",
    "                Default is \"\"\n",
    "            selection_no_windturbines_paths: pathlib.Path, pathlib.Path(\"\")\n",
    "                Set a list of paths to selection__no_windturbine folders in pathlib.Path format following the folder convention.\n",
    "                Default is \"\"\n",
    "            image_bands: list, [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "                Set the preferred image bands for the image.\n",
    "                Default is [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "            \n",
    "            Parameters for data preprocessing\n",
    "            ----------\n",
    "            rescale_factor: int, >0\n",
    "                Set a rescale factor for the image preprocessing in order to get values between 0 and 1.\n",
    "                Default is 2**14\n",
    "            rotation_range: int, 0 to 180\n",
    "                Set a value to randomly rotate images in the range (degrees, 0 to 180)\n",
    "                Default is 10\n",
    "            zoom_range: float or [lower, upper] \n",
    "                Set a range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range].\n",
    "                Default is 0.1\n",
    "            width_shift_range: float, 1-D array-like or int \n",
    "                Set a value in order to shift the image width wise.\n",
    "                Default is 0.1\n",
    "            height_shift_range: float, 1-D array-like or int \n",
    "                Set a value in order to shift the image height wise.\n",
    "                Default is 0.1   \n",
    "            horizontal_flip: Boolean, True or False\n",
    "                Set a value to randomly flip inputs horizontally.\n",
    "                Default is False\n",
    "            vertical_flip: Boolean, True or False\n",
    "                Set a value to randomly flip inputs vertically.\n",
    "                Default is False\n",
    "            fill_mode: str, (\"constant\", \"nearest\", \"reflect\" or \"wrap\"). \n",
    "                Set a mode for the fillmode. Points outside the boundaries of the input are filled according \n",
    "                to the given mode: 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)\n",
    "                                   'nearest': aaaaaaaa|abcd|dddddddd\n",
    "                                   'reflect': abcddcba|abcd|dcbaabcd\n",
    "                                   'wrap': abcdabcd|abcd|abcdabcd\n",
    "                Default is \"constant\"\n",
    "            cval: Float or Int \n",
    "                Value used for points outside the boundaries when fill_mode = \"constant\".\n",
    "                Default is 0.0\n",
    "            \n",
    "            Parameters for building the convolutional neural network CNN\n",
    "            ----------\n",
    "            num_cnn_layers: int, >0\n",
    "                Set the number of layers for the CNN.\n",
    "                If changed number of kernel_sizes list has to changed accordingly.\n",
    "                Default is 2\n",
    "            filters: int, (16, 32, 64 ...)\n",
    "                Set the number of filters used for the first layer (this mount is doubled each layer). \n",
    "                Default is 16\n",
    "            kernel_sizes: list of int, [kernel size layer 1, kernel size layer 2, ...]\n",
    "                Set the kernel size for each layer, first element corresponds to first layer etc..\n",
    "                The amount of kernel sizes has to be equal to the number of cnn layers.\n",
    "                Default is [5, 5]\n",
    "            layer_activations: str, (\"relu\", \"tanh\", \"sigmoid\"... see more on keras.activations)\n",
    "                Set the activaiton functions for each layer, first element corresponds to first layer etc..\n",
    "                The amount of activation functions has to be equal to the number of cnn layers.\n",
    "                Default is [\"relu\", \"relu\"]\n",
    "            input_shape: list, [rows, cols, channels]\n",
    "                Set the shape of the input image.\n",
    "                Default is [30, 30, 4]\n",
    "            pool_size: int, >0\n",
    "                Set the pool size of max pooling.\n",
    "                Default is 2\n",
    "            strides: int, >0\n",
    "                Set the strides of max pooling.\n",
    "                Default is 2\n",
    "            full_connection_units: int, >0\n",
    "                Set the dimensionality of the full connection outer space.\n",
    "                Default is 128\n",
    "            full_connection_activation: str, (\"relu\", \"tanh\", \"sigmoid\"... see more on keras.activations)\n",
    "                Set the activation function of the full connection (ANN) layer.\n",
    "                Default is \"relu\"\n",
    "            output_units: int, >0\n",
    "                Set the dimensionality of the output outer space.\n",
    "                Default is 1\n",
    "            output_activation: str, (\"relu\", \"tanh\", \"sigmoid\"... see more on keras.activations)\n",
    "                Set the activation function of the output layer.\n",
    "                Default is \"sigmoid\"\n",
    "                \n",
    "            Parameters for training the convolutional neural network CNN\n",
    "            ----------\n",
    "            optimizer: str, (\"adam\"... see more on keras.optimizers)\n",
    "                Set the optimizer function of the cnn compiling stage.\n",
    "                Default is \"adam\"\n",
    "            loss: str, (\"binary_crossentropy\"... see more on keras.losses)\n",
    "                Set the loss function of the cnn compiling stage.\n",
    "                Default is \"binary_crossentropy\"\n",
    "            metrics: list of str, ([\"accuracy\"] ... see more on keras.metrics)\n",
    "                Set the metrics of the cnn compiling stage.\n",
    "                Default is [\"accuracy\"]\n",
    "            epochs: int, >0\n",
    "                Set the number of epochs to train the model.\n",
    "                Default is 10\n",
    "            \"\"\"\n",
    "\n",
    "            self.categories_windturbine_crops = categories_windturbine_crops\n",
    "            self.categories_no_windturbine_crops = categories_no_windturbine_crops\n",
    "            self.pixel = pixel\n",
    "            self.selection_windturbine_paths = selection_windturbine_paths\n",
    "            self.selection_no_windturbine_paths = selection_no_windturbine_paths\n",
    "            self.image_bands = image_bands\n",
    "            self.rescale_factor = rescale_factor\n",
    "            self.rotation_range = rotation_range\n",
    "            self.zoom_range = zoom_range\n",
    "            self.width_shift_range = width_shift_range\n",
    "            self.height_shift_range = height_shift_range\n",
    "            self.horizontal_flip = horizontal_flip\n",
    "            self.vertical_flip = vertical_flip\n",
    "            self.fill_mode = fill_mode\n",
    "            self.cval = cval\n",
    "            self.num_cnn_layers = num_cnn_layers\n",
    "            self.filters = filters\n",
    "            self.kernel_sizes = kernel_sizes\n",
    "            self.layer_activations = layer_activations\n",
    "            self.input_shape = input_shape\n",
    "            self.pool_size = pool_size\n",
    "            self.strides = strides\n",
    "            self.full_connection_units = full_connection_units\n",
    "            self.full_connection_activation = full_connection_activation\n",
    "            self.output_units = output_units\n",
    "            self.output_activation = output_activation\n",
    "            self.optimizer = optimizer\n",
    "            self.loss = loss\n",
    "            self.metrics = metrics\n",
    "            self.epochs = epochs\n",
    "            \n",
    "            self.cnn = None\n",
    "            self.indices = []\n",
    "            self.indices_train = []\n",
    "            self.indices_test = []\n",
    "            self.X_train = None\n",
    "            self.X_test = None\n",
    "            self.y_train = None\n",
    "            self.y_test = None\n",
    "            self.confusion_matrix = None\n",
    "            self.accuracy_score = None\n",
    "            \n",
    "\n",
    "    def get_images_from_path(self, windturbines, categories, path=\"\"):\n",
    "        \"\"\"Expects a pathlib path and windturbine paramter (0 = no windturbine, 1 = windturbine)\n",
    "        Returns the independent variable four dimensional numpy array with every image bands, categories \n",
    "        and pixel shape selected by the user of every crop inside the folders. Also this function returns\n",
    "        the dependent variable vector (windturbine: Yes/No) corresponding to the independent variable array\n",
    "        (images).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        windtubines: int, (1 or 0)\n",
    "            Set the parameter to either 1 for data with windturbines and 0 without windturbines.\n",
    "            There is no default!\n",
    "        categories: list, [1,2,3] or [1,2]\n",
    "            Set one or more categories of the selection. \n",
    "            There is no default!\n",
    "        path: pathlib.Path, pathlib.Path(\"\")\n",
    "            Set a list of paths to sentinal image folders in pathlib.Path format following the folder convention.\n",
    "            Default is \"\"\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        X_images: list, 4D array\n",
    "            Returns a 4D list with images of every folder inside the given path\n",
    "        y_images: list, 1D array\n",
    "            Returns a 1D list with 1s (windturbines) or 0s (no windturbines) corresponding to given input\n",
    "        \"\"\"\n",
    "        \n",
    "        X_images = []\n",
    "        y_images = []\n",
    "\n",
    "        # loop through every category inside the selected windturbine crop folder\n",
    "        for category in path.glob(\"*\"):\n",
    "            # only select categories and pixel shape selected by the user\n",
    "            if category.name.count(\"_\") == 3:\n",
    "                if int(category.name.split(\"_\")[1]) in categories and category.name.split(\"_\")[3] == self.pixel:\n",
    "                    for crop in category.glob(\"*\"):\n",
    "                        if crop.is_dir() and crop.name != \"0_combined-preview\":\n",
    "\n",
    "                            image_path = crop / \"sensordata\" / \"R10m\"\n",
    "                            image_list = np.array([])\n",
    "\n",
    "                            # append every user selected image band to a list\n",
    "                            for element in image_path.glob(\"*_*_B*_10m.jp2\"):\n",
    "                                if element.name.split(\"_\")[2] in self.image_bands:\n",
    "                                    with rasterio.open(str(element)) as f:\n",
    "                                        if image_list.size == 0:\n",
    "                                            image_list = f.read(indexes=1)\n",
    "                                        else:\n",
    "                                            image_list = np.dstack((image_list, f.read(indexes=1)))\n",
    "\n",
    "                            X_images.append(image_list)\n",
    "                            y_images.append(windturbines)\n",
    "                            self.indices.append(crop.name.split(\"_\")[0])\n",
    "        \n",
    "        return X_images, y_images \n",
    "    \n",
    "    \n",
    "    def create_wt_identification_data(self):\n",
    "        \"\"\"Takes in path lists for windturbine and no windturbine image crops, appends every image to an array\n",
    "        and simultaniously adds a factorial variable to another list which indicates if the image contains a windturbine\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selection_windturbines_path: pathlib.Path, pathlib.Path(\"\")\n",
    "            Set a list of paths to selection_windturbine folders in pathlib.Path format following the folder convention.\n",
    "            Default is \"\"\n",
    "        selection_no_windturbines_paths: pathlib.Path, pathlib.Path(\"\")\n",
    "            Set a list of paths to selection__no_windturbine folders in pathlib.Path format following the folder convention.\n",
    "            Default is \"\"\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        X: list, 4D array\n",
    "            Returns a 4D list with images of every folder inside the given paths\n",
    "        y: list, 1D array\n",
    "            Returns a 1D list with 1s (windturbines) and 0s (no windturbines)\n",
    "        \"\"\"\n",
    "        \n",
    "        # initialize the independent and dependent variable\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for path in self.selection_windturbine_paths:\n",
    "            X_images, y_images = self.get_images_from_path(windturbines=1, categories=self.categories_windturbine_crops,\n",
    "                                                           path=path)\n",
    "            X.extend(X_images)\n",
    "            y.extend(y_images)\n",
    "\n",
    "        for path in self.selection_no_windturbine_paths:\n",
    "            X_images, y_images = self.get_images_from_path(windturbines=0, categories=self.categories_no_windturbine_crops,\n",
    "                                                           path=path)\n",
    "            X.extend(X_images)\n",
    "            y.extend(y_images)\n",
    "        \n",
    "        X = np.array(X)\n",
    "    \n",
    "        return X, y\n",
    "        \n",
    "        \n",
    "    def preprocess_data(self, X, y):\n",
    "        \n",
    "        train_datagen = ImageDataGenerator(rescale = 1./self.rescale_factor,\n",
    "                                           rotation_range=self.rotation_range,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                                           zoom_range=self.zoom_range, # Randomly zoom image \n",
    "                                           width_shift_range=self.width_shift_range,  # randomly shift images horizontally (fraction of total width)\n",
    "                                           height_shift_range=self.height_shift_range,  # randomly shift images vertically (fraction of total height)\n",
    "                                           horizontal_flip=self.horizontal_flip,  # randomly flip images\n",
    "                                           vertical_flip=self.vertical_flip,  # randomly flip images\n",
    "                                           fill_mode=self.fill_mode, cval=self.cval)\n",
    "        dataset = train_datagen.flow(x=X, y=y)\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    \n",
    "    def build_CNN(self):\n",
    "        \n",
    "        # Initialize CNN\n",
    "        cnn = tf.keras.models.Sequential()\n",
    "        \n",
    "        # Step 1: Convolution and pooling of layers\n",
    "        for i in range(1, self.num_cnn_layers+1):\n",
    "            if i == 1:\n",
    "                # First layer of the cnn\n",
    "                cnn.add(tf.keras.layers.Conv2D(filters=self.filters*i, kernel_size=self.kernel_sizes[0], activation=self.layer_activations[0], input_shape=self.input_shape))\n",
    "                cnn.add(tf.keras.layers.MaxPool2D(pool_size=self.pool_size, strides=self.strides))\n",
    "            else:\n",
    "                # Creation of more layers depending on the num_cnn_layers variable\n",
    "                cnn.add(tf.keras.layers.Conv2D(filters=self.filters*i, kernel_size=self.kernel_sizes[i-1], activation=self.layer_activations[i-1]))\n",
    "                cnn.add(tf.keras.layers.MaxPool2D(pool_size=self.pool_size, strides=self.strides))\n",
    "        \n",
    "        # Step 2: Flattening\n",
    "        cnn.add(tf.keras.layers.Flatten())\n",
    "        \n",
    "        # Step 3: Full connection\n",
    "        cnn.add(tf.keras.layers.Dense(units=self.full_connection_units, activation=self.full_connection_activation))\n",
    "        \n",
    "        # Step 4: Output Layer\n",
    "        cnn.add(tf.keras.layers.Dense(units=self.output_units, activation=self.output_activation))\n",
    "        \n",
    "        return cnn\n",
    "    \n",
    "    \n",
    "    def train_CNN(self, cnn, training_set, test_set):\n",
    "        \n",
    "        # Step 1: compiling the CNN\n",
    "        cnn.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics)\n",
    "        \n",
    "        # Step 2: Training the CNN on the Training set and evaluating it on the Test set\n",
    "        cnn.fit(x=training_set, validation_data=test_set, epochs=self.epochs)\n",
    "        \n",
    "        return cnn\n",
    "    \n",
    "    \n",
    "    def create_confusion_matrix(self):\n",
    "        \n",
    "        y_pred = self.cnn.predict(self.X_test)\n",
    "        y_pred = y_pred.astype(int)\n",
    "        \n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        ac = accuracy_score(self.y_test, y_pred)\n",
    "        \n",
    "        return cm, ac\n",
    "    \n",
    "    \n",
    "    def predict_single_observation(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def detect_windturbines_with_CNN(self):\n",
    "\n",
    "        # 1. Import the data:\n",
    "        print(\"\\nImporting data:\")\n",
    "        print(\"-----------------\\n\")\n",
    "        X, y = self.create_wt_identification_data()\n",
    "\n",
    "        # 2. Split data into training and test data:\n",
    "        print(\"\\nSplitting data:\")\n",
    "        print(\"-----------------\\n\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "        # 2.1. Randomize and split the indices with the same random_state in order to keep the indices of the crops\n",
    "        X_train, X_test, indices_train, indices_test = train_test_split(X, self.indices, test_size = 0.2, random_state = 0)\n",
    "        self.indices_train = indices_train\n",
    "        self.indices_test = indices_test\n",
    "\n",
    "        # 3. Preprocess the data:\n",
    "        print(\"\\nPreprocessing data:\")\n",
    "        print(\"-----------------\\n\")\n",
    "        training_set = self.preprocess_data(X_train, y_train)\n",
    "        test_set = self.preprocess_data(X_test, y_test)\n",
    "        \n",
    "        # 4. Build the CNN:\n",
    "        print(\"\\nBuilding the CNN:\")\n",
    "        print(\"-----------------\\n\")\n",
    "        cnn = self.build_CNN()\n",
    "        \n",
    "        # 5. Compile, train and evaluate the CNN:\n",
    "        print(\"\\nCompiling, training and evaluating the CNN:\")\n",
    "        print(\"-----------------\\n\")\n",
    "        cnn = self.train_CNN(cnn, training_set, test_set)\n",
    "        self.cnn = cnn\n",
    "        \n",
    "        # 6. Create confusion matrix and accuracy score:\n",
    "        print(\"\\nCreate confusion matrix and calculate accuracy score:\")\n",
    "        print(\"-----------------\\n\")\n",
    "        cm, ac = self.create_confusion_matrix()\n",
    "        self.confusion_matrix = cm\n",
    "        self.accuracy_score = ac\n",
    "        \n",
    "        print(\"\\nDone! CNN object available through .cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = WindturbineDetector(selection_windturbine_paths=[Path(\"/data/projects/windturbine-identification-sentinel/croppedTiles/us-uswtdb_selection_windturbines\")], \n",
    "                             selection_no_windturbine_paths=[Path(\"/data/projects/windturbine-identification-sentinel/croppedTiles/selection_no-windturbines\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importing data:\n",
      "-----------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbroethaler/.conda/envs/machine_learning/lib/python3.6/site-packages/rasterio/__init__.py:193: UserWarning: Dataset has no geotransform set.  Default transform will be applied (Affine.identity())\n",
      "  s.start()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data:\n",
      "-----------------\n",
      "\n",
      "\n",
      "Preprocessing data:\n",
      "-----------------\n",
      "\n",
      "\n",
      "Building the CNN:\n",
      "-----------------\n",
      "\n",
      "\n",
      "Compiling, training and evaluating the CNN:\n",
      "-----------------\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "Epoch 1/10\n",
      "236/236 [==============================] - 19s 79ms/step - loss: 0.4921 - accuracy: 0.7586 - val_loss: 0.3198 - val_accuracy: 0.8694\n",
      "Epoch 2/10\n",
      "236/236 [==============================] - 19s 81ms/step - loss: 0.2416 - accuracy: 0.9160 - val_loss: 0.1572 - val_accuracy: 0.9443\n",
      "Epoch 3/10\n",
      "236/236 [==============================] - 21s 90ms/step - loss: 0.1557 - accuracy: 0.9459 - val_loss: 0.1342 - val_accuracy: 0.9522\n",
      "Epoch 4/10\n",
      "236/236 [==============================] - 21s 90ms/step - loss: 0.1216 - accuracy: 0.9606 - val_loss: 0.1243 - val_accuracy: 0.9528\n",
      "Epoch 5/10\n",
      "236/236 [==============================] - 15s 65ms/step - loss: 0.1069 - accuracy: 0.9627 - val_loss: 0.1213 - val_accuracy: 0.9586\n",
      "Epoch 6/10\n",
      "236/236 [==============================] - 20s 85ms/step - loss: 0.1029 - accuracy: 0.9651 - val_loss: 0.1083 - val_accuracy: 0.9607\n",
      "Epoch 7/10\n",
      "236/236 [==============================] - 9s 37ms/step - loss: 0.0888 - accuracy: 0.9699 - val_loss: 0.1046 - val_accuracy: 0.9687\n",
      "Epoch 8/10\n",
      "236/236 [==============================] - 10s 41ms/step - loss: 0.0841 - accuracy: 0.9697 - val_loss: 0.1030 - val_accuracy: 0.9607\n",
      "Epoch 9/10\n",
      "236/236 [==============================] - 18s 77ms/step - loss: 0.0748 - accuracy: 0.9754 - val_loss: 0.0811 - val_accuracy: 0.9697\n",
      "Epoch 10/10\n",
      "236/236 [==============================] - 15s 63ms/step - loss: 0.0758 - accuracy: 0.9732 - val_loss: 0.0693 - val_accuracy: 0.9761\n",
      "\n",
      "Create confusion matrix and calculate accuracy score:\n",
      "-----------------\n",
      "\n",
      "\n",
      "Done! CNN object available through .cnn\n"
     ]
    }
   ],
   "source": [
    "test.detect_windturbines_with_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image with index 2070 has a windturbine\n"
     ]
    }
   ],
   "source": [
    "# Predict if a windturbine is on a located on a specific image\n",
    "index = 0\n",
    "image_to_predict = np.expand_dims(test.X_test[index], axis = 0)\n",
    "result = test.cnn.predict(image_to_predict)\n",
    "\n",
    "# find image ID\n",
    "image_index = test.indices_test[index]\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    print(f\"The image with index {image_index} has a windturbine\")\n",
    "else:\n",
    "    print(f\"The image with index {image_index} has NO windturbine\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-machine_learning]",
   "language": "python",
   "name": "conda-env-.conda-machine_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
